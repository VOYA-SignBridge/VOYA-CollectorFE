import { useEffect, useRef, useState, useCallback } from "react";
import { Hands, HAND_CONNECTIONS } from "@mediapipe/hands";
import { Camera } from "@mediapipe/camera_utils";
import * as drawing from "@mediapipe/drawing_utils";
import Button from "./ui/Button";
import Badge from "./ui/Badge";
import type { MediaPipeLandmark, CameraInfo, QualityInfo } from "../types";
import { OneEuroFilter } from "../utils/oneEuro";
import { TARGET_FRAMES, CAPTURE_COUNT, FRAME_INTERVAL_MS } from "../config/capture";
import SpeechInputButton from "./SpeechInputButton";

// Use module-scope fixed constants so they are stable across renders and
// won't need to be added to hook dependency arrays.
const FIXED_TARGET_FRAMES = TARGET_FRAMES;
const FIXED_CAPTURE_COUNT = CAPTURE_COUNT;

const parseBoolEnv = (value: unknown, fallback: boolean) => {
  if (typeof value !== 'string') return fallback;
  const v = value.trim().toLowerCase();
  if (v === '1' || v === 'true' || v === 'yes' || v === 'on') return true;
  if (v === '0' || v === 'false' || v === 'no' || v === 'off') return false;
  return fallback;
};

// Default to selfie-style mirroring (front camera usually feels "correct" mirrored).
// Override with `VITE_MIRROR_PREVIEW=0` if you want a non-mirrored, third-person view.
const MIRROR_PREVIEW = parseBoolEnv(import.meta.env.VITE_MIRROR_PREVIEW, true);
// If MediaPipe handedness feels swapped for your setup, enable this.
const SWAP_HANDEDNESS = parseBoolEnv(import.meta.env.VITE_SWAP_HANDEDNESS, false);

interface FullscreenCaptureModalProps {
  isOpen: boolean;
  onClose: () => void;
  onSampleCapture: (frames: Array<{
    left_hand: MediaPipeLandmark[];
    right_hand: MediaPipeLandmark[];
  }>, label: string, user: string, meta?: { camera_info?: CameraInfo; quality_info?: QualityInfo; dialect?: string }) => void;
  initialLabel?: string;
  initialUser?: string;
  targetFrames?: number;
  captureCount?: number;
}

export default function FullscreenCaptureModal({ 
  isOpen, 
  onClose, 
  onSampleCapture,
  initialLabel = "",
  initialUser = "",
  targetFrames = 60,
  captureCount = 1
}: FullscreenCaptureModalProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const cameraRef = useRef<Camera | null>(null);
  const rootRef = useRef<HTMLDivElement | null>(null);
  
  const [recording, setRecording] = useState(false);
  const [frames, setFrames] = useState<Array<{
    left_hand: MediaPipeLandmark[];
    right_hand: MediaPipeLandmark[];
  }>>([]);
  const [label, setLabel] = useState(initialLabel);
  const [user, setUser] = useState(initialUser);
  const [dialect, setDialect] = useState<string>("B·∫Øc");
  const [dialectList, setDialectList] = useState<string[]>(["B·∫Øc", "Trung", "Nam", "C·∫ßn Th∆°"]);
  const [countdown, setCountdown] = useState(0);
  const [isReady, setIsReady] = useState(false);
  const [paused, setPaused] = useState(false);
  
  // New state for capture management
  const [currentCaptureIndex, setCurrentCaptureIndex] = useState(0);
  const [completedCaptures, setCompletedCaptures] = useState(0);
  const [showTips, setShowTips] = useState(false);
  const [showGuide, setShowGuide] = useState(false);
  // Small mode state for HUD and behavior introspection
  const [mode, setMode] = useState<'IDLE' | 'COUNTDOWN' | 'RECORD'>('IDLE');
  // Track whether hands are currently visible to gate frame capture
  const [handsVisible, setHandsVisible] = useState(false);
  // Quick suggestions for signer name (shared across pages via localStorage)
  const [recentUsers, setRecentUsers] = useState<string[]>(() => {
    try {
      const raw = localStorage.getItem('recentSigners');
      const parsed = raw ? JSON.parse(raw) : [];
      if (Array.isArray(parsed)) {
        return parsed.filter((x) => typeof x === 'string').slice(0, 5);
      }
    } catch {
      // ignore
    }
    return [];
  });
  
  // Refs to prevent stale closures
  const recordingRef = useRef(false);
  const pausedRef = useRef(false);
  const framesRef = useRef<Array<{
    left_hand: MediaPipeLandmark[];
    right_hand: MediaPipeLandmark[];
  }>>([]);
  const modeRef = useRef<typeof mode>(mode);
  const rememberUser = useCallback((name: string) => {
    const trimmed = name.trim();
    if (!trimmed) return;
    setRecentUsers((prev) => {
      const next = [trimmed, ...prev.filter((x) => x !== trimmed)].slice(0, 5);
      try {
        localStorage.setItem('recentSigners', JSON.stringify(next));
      } catch {
        // ignore
      }
      return next;
    });
  }, []);
  
  // Add frame interval control for better training data. Use centralized config.
  const lastFrameTimeRef = useRef(0);
  // Default sampling rate is defined in `src/config/capture.ts` as SAMPLE_FPS
  // FRAME_INTERVAL_MS is computed there (Math.round(1000 / SAMPLE_FPS)).
  const frameIntervalMs = useRef(FRAME_INTERVAL_MS);

  // Helper to compute lightweight quality metrics for a captured frameset
  const computeQuality = useCallback((capturedFrames: Array<{
    left_hand: MediaPipeLandmark[];
    right_hand: MediaPipeLandmark[];
  }>) => {
    let totalHandLandmarks = 0;
    let framesWithHands = 0;
    let framesAccepted = 0;
    let confidenceSum = 0;
    let confidenceCount = 0;

    for (const f of capturedFrames) {
      const leftCount = (f.left_hand || []).length;
      const rightCount = (f.right_hand || []).length;
      const handCount = leftCount + rightCount;
      totalHandLandmarks += handCount;
      const hasHands = handCount > 0;
      if (hasHands) framesWithHands++;

      // approximate confidence if landmark has visibility field
      const landmarks = [...(f.left_hand || []), ...(f.right_hand || [])];
      let frameConfSum = 0;
      let frameConfCnt = 0;
      for (const lm of landmarks) {
        if (typeof lm.visibility === 'number') {
          frameConfSum += lm.visibility;
          frameConfCnt++;
        }
      }
      if (frameConfCnt > 0) {
        confidenceSum += frameConfSum;
        confidenceCount += frameConfCnt;
      }

      // Acceptance: require at least one hand landmark
      if (handCount > 0) framesAccepted++;
    }

    const quality: QualityInfo = {
      framesCollected: capturedFrames.length,
      framesAccepted,
  avgPoseLandmarksPerFrame: capturedFrames.length ? totalHandLandmarks / capturedFrames.length : 0,
      percentFramesWithHands: capturedFrames.length ? (framesWithHands / capturedFrames.length) * 100 : 0,
      confidenceSummary: confidenceCount ? { avg: confidenceSum / confidenceCount } : undefined,
    };

    return quality;
  // FIXED_CAPTURE_COUNT and FIXED_TARGET_FRAMES are stable module constants; disable exhaustive-deps warning
  // FIXED_CAPTURE_COUNT and FIXED_TARGET_FRAMES are module-level constants and do not change at runtime.
  // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // keep modeRef in sync for render loop access
  useEffect(() => {
    modeRef.current = mode;
  }, [mode]);
  
  // Add canvas rendering optimization
  const pendingRenderRef = useRef(false);
  const renderDataRef = useRef<{
    poseLandmarks?: MediaPipeLandmark[];
    leftHandLandmarks?: MediaPipeLandmark[];
    rightHandLandmarks?: MediaPipeLandmark[];
    image?: HTMLImageElement | HTMLVideoElement;
  } | null>(null);

  // Filters for smoothing landmarks (keyed by group.index.coord)
  const filtersRef = useRef<Record<string, OneEuroFilter>>({});

  // Fixed filter parameters for simplified public uploader
  const filterMinCutoff = 1.0; // higher = more responsive, less smoothing
  const filterBeta = 0.01; // higher = more adaptive to speed
  // Render smoothing (lerp) - higher = more immediate (0.0 very smooth, 1.0 raw)
  const renderAlpha = 0.85;

  const getFilter = useCallback((key: string) => {
    if (!filtersRef.current[key]) {
      // create using live params
      filtersRef.current[key] = new OneEuroFilter(30, filterMinCutoff, filterBeta, 1.0);
    }
    return filtersRef.current[key];
  }, []);

  const filterLandmarks = useCallback((landmarks: MediaPipeLandmark[] | undefined, group = 'pose') => {
    if (!landmarks) return [] as MediaPipeLandmark[];
    const now = Date.now();
    return landmarks.map((lm, idx) => {
      const kx = `${group}.${idx}.x`;
      const ky = `${group}.${idx}.y`;
      const kz = `${group}.${idx}.z`;
      const kv = `${group}.${idx}.v`;
      const fx = getFilter(kx).filter(lm.x ?? 0, now);
      const fy = getFilter(ky).filter(lm.y ?? 0, now);
      const fz = getFilter(kz).filter(lm.z ?? 0, now);
      const fv = typeof lm.visibility === 'number' ? getFilter(kv).filter(lm.visibility, now) : lm.visibility;
      return { ...lm, x: fx, y: fy, z: fz, visibility: fv } as MediaPipeLandmark;
    });
  }, [getFilter]);

  // Filters use fixed parameters in this simplified modal; no dynamic clearing required

  // Low-latency render state (lerp towards raw each frame) to reduce perceived lag
  const renderPrevRef = useRef<Record<string, MediaPipeLandmark>>({});

  // Simple temporal smoothing for hand presence and preview stability
  const PRESENCE_HISTORY_SIZE = 5;
  const leftPresenceHistoryRef = useRef<boolean[]>([]);
  const rightPresenceHistoryRef = useRef<boolean[]>([]);
  const visibilityStateRef = useRef<{ left: boolean; right: boolean }>({ left: false, right: false });
  const lastRenderedLeftRef = useRef<MediaPipeLandmark[] | undefined>(undefined);
  const lastRenderedRightRef = useRef<MediaPipeLandmark[] | undefined>(undefined);

  const lerp = (a: number, b: number, t: number) => a + (b - a) * t;

  const getRenderLandmarks = useCallback((raw: MediaPipeLandmark[] | undefined, group = 'pose') => {
    if (!raw) return [] as MediaPipeLandmark[];
    const prev = renderPrevRef.current;
    const alpha = Math.max(0, Math.min(1, renderAlpha));
    return raw.map((lm, idx) => {
      const key = `${group}.${idx}`;
      const prevLm = prev[key];
      const tx = lm.x ?? 0;
      const ty = lm.y ?? 0;
      const tz = lm.z ?? 0;
      const tv = typeof lm.visibility === 'number' ? lm.visibility : undefined;
      if (!prevLm) {
        const newLm = { ...lm } as MediaPipeLandmark;
        prev[key] = newLm;
        return newLm;
      }
      const nx = lerp(prevLm.x ?? tx, tx, alpha);
      const ny = lerp(prevLm.y ?? ty, ty, alpha);
      const nz = lerp(prevLm.z ?? tz, tz, alpha);
      const nv = typeof tv === 'number' ? lerp((prevLm.visibility as number) ?? tv, tv, alpha) : (prevLm.visibility as number | undefined);
      const out: MediaPipeLandmark = { ...lm, x: nx, y: ny, z: nz, visibility: typeof nv === 'number' ? nv : undefined };
      prev[key] = out;
      return out;
    });
  }, [renderAlpha]);

  // Optimized rendering function
  const renderLandmarks = useCallback(() => {
    const canvas = canvasRef.current;
    const video = videoRef.current;
    const data = renderDataRef.current;
    
    if (!canvas || !data) return;
    
    const ctx = canvas.getContext("2d", { alpha: false }); // Disable alpha for performance
    if (!ctx) return;

    // Clear and draw video
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    ctx.save();
    if (MIRROR_PREVIEW) {
      ctx.translate(canvas.width, 0);
      ctx.scale(-1, 1);
    }

    if (video && video.readyState >= 2 && video.videoWidth > 0) {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    } else if (data.image) {
      ctx.drawImage(data.image, 0, 0, canvas.width, canvas.height);
    }

    // Draw landmarks with simplified styling for better performance
    if (data.leftHandLandmarks) {
      // @ts-expect-error - HAND_CONNECTIONS types from mediapipe are not available in this project
      drawing.drawConnectors(ctx, data.leftHandLandmarks, HAND_CONNECTIONS, {
        color: "#FF6B35",
        lineWidth: 2
      });
      drawing.drawLandmarks(ctx, data.leftHandLandmarks, {
        color: "#FF6B35",
        radius: 5
      });
    }

    if (data.rightHandLandmarks) {
      // @ts-expect-error - HAND_CONNECTIONS types from mediapipe are not available in this project
      drawing.drawConnectors(ctx, data.rightHandLandmarks, HAND_CONNECTIONS, {
        color: "#4ECDC4",
        lineWidth: 2
      });
      drawing.drawLandmarks(ctx, data.rightHandLandmarks, {
        color: "#4ECDC4",
        radius: 5
      });
    }

    ctx.restore();

    // Draw HUD (MODE / HANDS / FRAMES / VISIBILITY / FLAGS) top-left
    try {
      const hudPadding = 8;
      const vis = visibilityStateRef.current;
      const lines = [
        `MODE: ${modeRef.current}`,
        `HANDS: ${((data.leftHandLandmarks?.length ?? 0) > 0 ? 1 : 0) + ((data.rightHandLandmarks?.length ?? 0) > 0 ? 1 : 0)}`,
        `FRAMES: ${framesRef.current.length}/${targetFramesRef.current}`,
        `VIS: L=${vis.left ? 'ON' : 'OFF'} R=${vis.right ? 'ON' : 'OFF'}`,
        `FLAGS: MIRROR=${MIRROR_PREVIEW ? 'ON' : 'OFF'} SWAP=${SWAP_HANDEDNESS ? 'ON' : 'OFF'}`
      ];
      ctx.save();
      ctx.font = '14px ui-sans-serif, system-ui, -apple-system, "Segoe UI", Roboto, "Helvetica Neue", Arial';
      ctx.textBaseline = 'top';
      let maxW = 0;
      for (const l of lines) {
        const m = ctx.measureText(l).width;
        if (m > maxW) maxW = m;
      }
      const boxW = Math.ceil(maxW + hudPadding * 2);
      const boxH = Math.ceil(lines.length * 18 + hudPadding * 2);

      // background
      ctx.fillStyle = 'rgba(0,0,0,0.45)';
      const rx = 12, ry = 12;
      const x = 12, y = 12;
      // Rounded rect
      ctx.beginPath();
      ctx.moveTo(x + rx, y);
      ctx.arcTo(x + boxW, y, x + boxW, y + boxH, ry);
      ctx.arcTo(x + boxW, y + boxH, x, y + boxH, rx);
      ctx.arcTo(x, y + boxH, x, y, ry);
      ctx.arcTo(x, y, x + boxW, y, rx);
      ctx.closePath();
      ctx.fill();

      // text
      ctx.fillStyle = '#fff';
      for (let i = 0; i < lines.length; i++) {
        ctx.fillText(lines[i], x + hudPadding, y + hudPadding + i * 18);
      }
      ctx.restore();
    } catch (e) {
      // guard - HUD drawing must not break main render
      // eslint-disable-next-line no-console
      console.warn('HUD draw failed', e);
    }
    
    pendingRenderRef.current = false;
  }, []);
  const labelRef = useRef(label);
  const userRef = useRef(user);
  const dialectRef = useRef(dialect);
  const targetFramesRef = useRef(targetFrames);
  const captureCountRef = useRef(captureCount);
  const onSampleCaptureRef = useRef(onSampleCapture);
  const handleCloseRef = useRef<() => void>(() => {});
  const completedCapturesRef = useRef(0);

  const handleClose = useCallback(() => {
    // If recording or there are partial frames, confirm before closing
    const partialFrames = framesRef.current?.length || 0;
    if (recordingRef.current || (partialFrames > 0 && partialFrames < targetFramesRef.current)) {
      const ok = window.confirm(`Capture ch∆∞a ho√†n t·∫•t (${partialFrames}/${targetFramesRef.current}) ‚Äî b·∫°n c√≥ mu·ªën tho√°t v√† b·ªè d·ªØ li·ªáu n√†y kh√¥ng?`);
      if (!ok) return;
    }

  setRecording(false);
  setMode('IDLE');
    setFrames([]);
    setCountdown(0);
    setIsReady(false);
    setCurrentCaptureIndex(0);
    setCompletedCaptures(0);
    
    // Exit browser fullscreen if active
    try {
      if (document.fullscreenElement) {
        // Requesting exit may return a promise
        document.exitFullscreen?.();
      }
    } catch (e) {
      // ignore fullscreen exit errors
    }

    // Stop camera and close video stream
    if (cameraRef.current) {
      cameraRef.current.stop();
      cameraRef.current = null;
    }
    
    // Stop video tracks
    if (videoRef.current && videoRef.current.srcObject) {
      const stream = videoRef.current.srcObject as MediaStream;
      stream.getTracks().forEach(track => track.stop());
      videoRef.current.srcObject = null;
    }
    
    onClose();
  }, [onClose]);

  // Request fullscreen when modal opens
  useEffect(() => {
    if (!isOpen) return;
    const root = rootRef.current;
    if (!root) return;

    // Try to enter browser fullscreen for the modal container
    try {
      // Vendor-prefixed fullscreen methods may exist on HTMLElement in some browsers
  type Fn = (...args: unknown[]) => unknown;
  const el = root as HTMLElement & Partial<Record<'webkitRequestFullscreen' | 'mozRequestFullScreen' | 'msRequestFullscreen' | 'requestFullscreen', Fn>>;
  const request = (el.requestFullscreen as Fn | undefined) ?? el.webkitRequestFullscreen ?? el.mozRequestFullScreen ?? el.msRequestFullscreen;
      if (request) {
        const maybe = request.call(el);
        if (maybe && typeof (maybe as Promise<unknown>).catch === 'function') {
          (maybe as Promise<unknown>).catch((err) => {
            console.warn('Fullscreen request failed:', err);
          });
        }
      }
    } catch (err) {
      // ignore
    }

    // When modal closes, ensure we exit fullscreen in cleanup
    return () => {
      try {
        if (document.fullscreenElement) {
          document.exitFullscreen?.();
        }
      } catch (e) {
        // ignore
      }
    };
  }, [isOpen]);
  
  // Update refs when state changes
  useEffect(() => {
    recordingRef.current = recording;
  }, [recording]);
  
  useEffect(() => {
    pausedRef.current = paused;
  }, [paused]);
  
  useEffect(() => {
    framesRef.current = frames;
  }, [frames]);

  useEffect(() => {
    labelRef.current = label;
  }, [label]);

  useEffect(() => {
    dialectRef.current = dialect;
  }, [dialect]);

  useEffect(() => {
    userRef.current = user;
  }, [user]);

  useEffect(() => {
    console.log('Component mounted with props:', { targetFrames, captureCount, initialLabel, initialUser });
    console.log('Initial targetFramesRef.current:', targetFramesRef.current);
  }, [targetFrames, captureCount, initialLabel, initialUser]);

  useEffect(() => {
    // Enforce fixed target frames for simplified UI
    targetFramesRef.current = FIXED_TARGET_FRAMES;
    console.log('targetFramesRef enforced to fixed value:', targetFramesRef.current);
  }, [targetFrames]);

  useEffect(() => {
    // Enforce fixed capture count for simplified UI
    captureCountRef.current = FIXED_CAPTURE_COUNT;
    console.log('captureCountRef enforced to fixed value:', captureCountRef.current);
  }, [captureCount]);

  useEffect(() => {
    onSampleCaptureRef.current = onSampleCapture;
  }, [onSampleCapture]);

  // Load persisted dialects & selection
  useEffect(() => {
    try {
      const stored = JSON.parse(localStorage.getItem('dialectList') || 'null');
      if (Array.isArray(stored) && stored.length > 0) {
        // Auto-merge C·∫ßn Th∆° if not present
        const merged = Array.from(new Set([...stored, 'C·∫ßn Th∆°']));
        setDialectList(merged);
        localStorage.setItem('dialectList', JSON.stringify(merged));
      } else {
        // Set default and save
        const defaultList = ["B·∫Øc", "Trung", "Nam", "C·∫ßn Th∆°"];
        setDialectList(defaultList);
        localStorage.setItem('dialectList', JSON.stringify(defaultList));
      }
      const storedSel = localStorage.getItem('dialectSelected');
      if (storedSel) setDialect(storedSel);
    } catch (e) {
      // ignore
    }
  }, []);

  useEffect(() => {
    handleCloseRef.current = handleClose;
  }, [handleClose]);

  useEffect(() => {
    completedCapturesRef.current = completedCaptures;
    console.log('completedCapturesRef updated to:', completedCaptures);
  }, [completedCaptures]);

  // Quick labels for fast selection
  // quickLabels removed for simplified public uploader

  // Handlers
  const handleQuickCapture = useCallback(() => {
    if (!labelRef.current || !userRef.current) return;
    // Reset capture state
    setFrames([]);
    framesRef.current = [];
    setCurrentCaptureIndex(0);
    setCompletedCaptures(0);
    completedCapturesRef.current = 0;
    
    // Reset frame timing
    lastFrameTimeRef.current = 0;
    
  setCountdown(3);
  setMode('COUNTDOWN');
    
  console.log(`Starting capture sequence: ${FIXED_CAPTURE_COUNT} captures of ${FIXED_TARGET_FRAMES} frames each`);
    
    setTimeout(() => {
      setRecording(true);
      recordingRef.current = true;
      setMode('RECORD');
      lastFrameTimeRef.current = Date.now(); // Start timing from recording start
    }, 3000);
  // FIXED_CAPTURE_COUNT and FIXED_TARGET_FRAMES are stable module constants and
  // intentionally omitted from dependencies to avoid unnecessary re-creations.
  }, []);

  const handlePause = useCallback(() => {
    setPaused(true);
    pausedRef.current = true;
    console.log('Recording paused at', framesRef.current.length, 'frames');
  }, []);

  const handleResume = useCallback(() => {
    setPaused(false);
    pausedRef.current = false;
    lastFrameTimeRef.current = Date.now(); // reset timing to avoid skip
    console.log('Recording resumed from', framesRef.current.length, 'frames');
  }, []);

  const handleRestart = useCallback(() => {
    // Discard current frames and restart from zero
    setFrames([]);
    framesRef.current = [];
    setPaused(false);
    pausedRef.current = false;
    lastFrameTimeRef.current = Date.now();
    console.log('Recording restarted from beginning');
  }, []);

  const handleStop = useCallback(() => {
    const collected = framesRef.current.length || 0;
    const required = targetFramesRef.current || 0;

    if (collected < required) {
      // Block stopping early ‚Äî inform the user to continue until enough frames
      window.alert(`B·∫°n ch∆∞a thu ƒë·ªß khung h√¨nh: ${collected}/${required}. Vui l√≤ng ti·∫øp t·ª•c quay cho ƒë·∫øn khi ƒë·ªß.`);
      return;
    }

    setRecording(false);
    recordingRef.current = false;
    setPaused(false);
    pausedRef.current = false;

      if (framesRef.current.length > 0) {
      const quality = computeQuality(framesRef.current);
      onSampleCaptureRef.current(framesRef.current, labelRef.current, userRef.current, { quality_info: quality, dialect: dialectRef.current });
      setFrames([]);
      framesRef.current = [];
    }
  }, [computeQuality]);

  useEffect(() => {
    if (!isOpen) return;

    console.log('Setting up camera and MediaPipe Hands...');

    const hands = new Hands({
      locateFile: (file: string) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`,
    });

    hands.setOptions({
      maxNumHands: 2,
      modelComplexity: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.6,
      minTrackingConfidence: 0.7,
    });

    console.log('MediaPipe Hands initialized');

    hands.onResults((results: unknown) => {
      const r = results as { multiHandLandmarks?: MediaPipeLandmark[][]; multiHandedness?: Array<{ label?: string; score?: number }>; image?: HTMLImageElement | HTMLVideoElement };

      let leftHandLandmarks: MediaPipeLandmark[] | undefined;
      let rightHandLandmarks: MediaPipeLandmark[] | undefined;
      // Simple per-frame mapping: use MediaPipe handedness labels with
      // optional global swap, without extra positional locking.
      if (r.multiHandLandmarks && r.multiHandedness && r.multiHandLandmarks.length === r.multiHandedness.length) {
        for (let i = 0; i < r.multiHandLandmarks.length; i++) {
          const lm = r.multiHandLandmarks[i] as MediaPipeLandmark[];
          const h = r.multiHandedness[i] as { label?: string };
          const rawLabel = h.label;
          const effectiveLabel = SWAP_HANDEDNESS
            ? rawLabel === 'Left'
              ? 'Right'
              : rawLabel === 'Right'
              ? 'Left'
              : rawLabel
            : rawLabel;

          if (effectiveLabel === 'Left' && !leftHandLandmarks) {
            leftHandLandmarks = lm;
          } else if (effectiveLabel === 'Right' && !rightHandLandmarks) {
            rightHandLandmarks = lm;
          }
        }
      }

      // --- Temporal smoothing for presence & preview ---
      const leftDetectedNow = !!(leftHandLandmarks && leftHandLandmarks.length > 0);
      const rightDetectedNow = !!(rightHandLandmarks && rightHandLandmarks.length > 0);

      // Update presence history (ring buffer style)
      leftPresenceHistoryRef.current.push(leftDetectedNow);
      if (leftPresenceHistoryRef.current.length > PRESENCE_HISTORY_SIZE) {
        leftPresenceHistoryRef.current.shift();
      }
      rightPresenceHistoryRef.current.push(rightDetectedNow);
      if (rightPresenceHistoryRef.current.length > PRESENCE_HISTORY_SIZE) {
        rightPresenceHistoryRef.current.shift();
      }

      const leftVotes = leftPresenceHistoryRef.current.filter(Boolean).length;
      const rightVotes = rightPresenceHistoryRef.current.filter(Boolean).length;
      const leftSmoothedVisible = leftVotes > leftPresenceHistoryRef.current.length / 2;
      const rightSmoothedVisible = rightVotes > rightPresenceHistoryRef.current.length / 2;

      visibilityStateRef.current = {
        left: leftSmoothedVisible,
        right: rightSmoothedVisible,
      };

      // Compute render landmarks with fallback to last non-empty frame
      let renderLeft: MediaPipeLandmark[] = [];
      let renderRight: MediaPipeLandmark[] = [];

      if (leftDetectedNow) {
        renderLeft = getRenderLandmarks(leftHandLandmarks, "leftHand");
        lastRenderedLeftRef.current = renderLeft;
      } else if (leftSmoothedVisible && lastRenderedLeftRef.current) {
        renderLeft = lastRenderedLeftRef.current;
      } else {
        lastRenderedLeftRef.current = undefined;
      }

      if (rightDetectedNow) {
        renderRight = getRenderLandmarks(rightHandLandmarks, "rightHand");
        lastRenderedRightRef.current = renderRight;
      } else if (rightSmoothedVisible && lastRenderedRightRef.current) {
        renderRight = lastRenderedRightRef.current;
      } else {
        lastRenderedRightRef.current = undefined;
      }

      renderDataRef.current = {
        leftHandLandmarks: renderLeft,
        rightHandLandmarks: renderRight,
        image: r.image as HTMLImageElement | HTMLVideoElement
      };

      if (!pendingRenderRef.current) {
        pendingRenderRef.current = true;
        requestAnimationFrame(renderLandmarks);
      }

      // Capture logic (hands-only)
      if (recordingRef.current && !pausedRef.current) {
        const currentTime = Date.now();
        if (currentTime - lastFrameTimeRef.current < frameIntervalMs.current) return;
        lastFrameTimeRef.current = currentTime;

        // Prefer current detection; if temporarily lost but smoothed presence is ON,
        // fall back to the last rendered landmarks to avoid empty frames.
        let captureLeft = leftHandLandmarks;
        let captureRight = rightHandLandmarks;

        if (!captureLeft && leftSmoothedVisible && lastRenderedLeftRef.current) {
          captureLeft = lastRenderedLeftRef.current;
        }
        if (!captureRight && rightSmoothedVisible && lastRenderedRightRef.current) {
          captureRight = lastRenderedRightRef.current;
        }

        const leftHas = (captureLeft?.length ?? 0) > 0;
        const rightHas = (captureRight?.length ?? 0) > 0;

        let leftVisible = false;
        let rightVisible = false;
        if (captureLeft) leftVisible = captureLeft.some(lm => typeof lm.visibility === 'number' ? lm.visibility >= 0.5 : true);
        if (captureRight) rightVisible = captureRight.some(lm => typeof lm.visibility === 'number' ? lm.visibility >= 0.5 : true);

        const anyHands = leftHas || rightHas;
        const anyVisible = leftVisible || rightVisible;

        // UI hint uses smoothed presence to reduce flicker
        setHandsVisible(leftSmoothedVisible || rightSmoothedVisible || anyHands || anyVisible);

        if (!(anyVisible || anyHands)) {
          console.log('Skipping frame: no hands detected');
        } else {
          const landmarks = {
            left_hand: filterLandmarks(captureLeft, 'leftHand') || [],
            right_hand: filterLandmarks(captureRight, 'rightHand') || [],
          };

          framesRef.current.push(landmarks);
        }

        setFrames([...framesRef.current]);
        console.log(`Recording progress: ${framesRef.current.length}/${targetFramesRef.current} frames`);

        if (framesRef.current.length >= FIXED_TARGET_FRAMES) {
          console.log('Target frames reached, stopping recording');
          recordingRef.current = false;
          setRecording(false);
          setMode('IDLE');

          const capturedFrames = [...framesRef.current];
          const quality = computeQuality(capturedFrames);
          const newCompleted = completedCapturesRef.current + 1;

          console.log(`Capture ${newCompleted} completed with ${capturedFrames.length} frames`);
          onSampleCaptureRef.current(capturedFrames, labelRef.current, userRef.current, { quality_info: quality, dialect: dialectRef.current });

          completedCapturesRef.current = newCompleted;
          setCompletedCaptures(newCompleted);
          setCurrentCaptureIndex(newCompleted);

          if (newCompleted < FIXED_CAPTURE_COUNT) {
            console.log(`Preparing capture ${newCompleted + 1} of ${FIXED_CAPTURE_COUNT}`);
            setFrames([]);
            framesRef.current = [];
            lastFrameTimeRef.current = 0;
            setTimeout(() => {
              setCountdown(3);
              setMode('COUNTDOWN');
              setTimeout(() => {
                setRecording(true);
                recordingRef.current = true;
                setMode('RECORD');
                lastFrameTimeRef.current = Date.now();
              }, 3000);
            }, 2000);
          } else {
            // Final capture completed. Keep the modal open, clear frames and
            // reset only the action label so the user can start a new capture
            // while preserving the same user ID.
            setTimeout(() => {
              // clear captured frames and reset timing
              setFrames([]);
              framesRef.current = [];
              lastFrameTimeRef.current = 0;

              // reset capture counters so UI shows ready state
              completedCapturesRef.current = 0;
              setCompletedCaptures(0);
              setCurrentCaptureIndex(0);

              // stop recording and set idle mode
              recordingRef.current = false;
              setRecording(false);
              setMode('IDLE');

              // clear the action label but keep the user id
              setLabel('');
            }, 1000);
          }
        }
      }
    });

    if (videoRef.current) {
      console.log('Video element found, setting up camera...');
      
      // Setup canvas size once
      const canvas = canvasRef.current;
      if (canvas) {
        canvas.width = 1280;
        canvas.height = 720;
        console.log('Canvas initialized to 1280x720');
      }
      
      // Add video event listeners for debugging
      const video = videoRef.current;
      
      const onLoadedMetadata = () => {
        console.log('Video metadata loaded:', {
          videoWidth: video.videoWidth,
          videoHeight: video.videoHeight,
          readyState: video.readyState
        });
      };
      
      const onCanPlay = () => {
        console.log('Video can play:', {
          videoWidth: video.videoWidth,
          videoHeight: video.videoHeight,
          readyState: video.readyState
        });
      };

      video.addEventListener('loadedmetadata', onLoadedMetadata);
      video.addEventListener('canplay', onCanPlay);

      console.log('Creating camera instance...');
      
      // Check camera permissions first
      navigator.mediaDevices.getUserMedia({ 
        video: { 
          width: 1280, 
          height: 720,
          frameRate: { ideal: 30, max: 60 } // Optimize camera FPS
        } 
      })
        .then((stream) => {
          console.log('Camera permission granted, stream:', stream);
          // Stop the test stream
          stream.getTracks().forEach(track => track.stop());
          
          // Now create the MediaPipe camera
      const camera = new Camera(videoRef.current!, {
            onFrame: async () => {
              if (videoRef.current) {
                await hands.send({ image: videoRef.current });
              }
            },
            width: 1280,
            height: 720,
            facingMode: 'user' // Ensure front camera for better performance
          });
          
          cameraRef.current = camera;
          console.log('Starting camera...');
          camera.start().then(() => {
            console.log('Camera started successfully! Video element:', {
              videoWidth: videoRef.current?.videoWidth,
              videoHeight: videoRef.current?.videoHeight,
              readyState: videoRef.current?.readyState,
              srcObject: !!videoRef.current?.srcObject
            });
            setIsReady(true);
          }).catch((error) => {
            console.error('Camera start failed:', error);
            setIsReady(false);
          });
        })
        .catch((error) => {
          console.error('Camera permission denied or not available:', error);
          setIsReady(false);
        });

      // Cleanup listeners
      return () => {
        video.removeEventListener('loadedmetadata', onLoadedMetadata);
        video.removeEventListener('canplay', onCanPlay);
        hands.close();
        if (cameraRef.current) {
          cameraRef.current.stop();
          cameraRef.current = null;
        }
      };
    }

    return () => {
      hands.close();
      if (cameraRef.current) {
        cameraRef.current.stop();
        cameraRef.current = null;
      }
    };
  // FIXED_CAPTURE_COUNT and FIXED_TARGET_FRAMES are stable module constants and
  // intentionally omitted from dependencies.
  }, [isOpen, renderLandmarks, computeQuality, filterLandmarks, getRenderLandmarks]); // Include renderLandmarks, computeQuality, filterLandmarks and getRenderLandmarks

  // Countdown effect
  useEffect(() => {
    console.log('Countdown effect triggered:', countdown, 'recording:', recording);
    if (countdown > 0) {
      console.log(`Countdown: ${countdown}`);
      const timer = setTimeout(() => setCountdown(countdown - 1), 1000);
      return () => clearTimeout(timer);
    } else if (countdown === 0 && recording) {
      console.log('Countdown finished, recording started');
      // Remove auto-timeout - let frame completion logic handle stopping
      console.log('Recording started, waiting for frame completion...');
      
      // Backup timeout only if frame completion fails (much longer)
      const backupTimer = setTimeout(() => {
        console.warn('BACKUP TIMEOUT: Frame completion failed after 30 seconds');
        handleStop();
      }, 30000);
      return () => clearTimeout(backupTimer);
    }
  }, [countdown, recording, handleStop]);

  // Cleanup on unmount
  useEffect(() => {
    const currentCamera = cameraRef.current;
    const currentVideo = videoRef.current;
    
    return () => {
      // Cleanup when component unmounts
      if (currentCamera) {
        currentCamera.stop();
      }
      if (currentVideo && currentVideo.srcObject) {
        const stream = currentVideo.srcObject as MediaStream;
        stream.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  // Keyboard shortcuts
  useEffect(() => {
    if (!isOpen) return;

    const handleKeyPress = (e: KeyboardEvent) => {
      // Don't trigger shortcuts when user is typing in an input/textarea or editable element
      const active = document.activeElement as HTMLElement | null;
      if (active && (active.tagName === 'INPUT' || active.tagName === 'TEXTAREA' || active.isContentEditable)) {
        return;
      }

      console.log('Key pressed:', e.code);

      if (e.code === 'Enter') {
        e.preventDefault();
        console.log('Enter pressed - recording:', recordingRef.current, 'label:', labelRef.current, 'user:', userRef.current);
        if (!recordingRef.current && labelRef.current && userRef.current) {
          // Inline quick capture logic
          setFrames([]);
          framesRef.current = [];
          setCurrentCaptureIndex(0);
          setCompletedCaptures(0);
          completedCapturesRef.current = 0;
          setCountdown(3);
          setMode('COUNTDOWN');
          
          console.log(`Starting capture sequence: ${captureCountRef.current} captures of ${targetFramesRef.current} frames each`);
          
          setTimeout(() => {
            setRecording(true);
            recordingRef.current = true;
            setMode('RECORD');
          }, 3000);
        } else if (recordingRef.current) {
          // Inline stop logic ‚Äî enforce target frames before allowing stop
          const collected = framesRef.current.length || 0;
          const required = targetFramesRef.current || 0;
          if (collected < required) {
            window.alert(`B·∫°n ch∆∞a thu ƒë·ªß khung h√¨nh: ${collected}/${required}. Vui l√≤ng ti·∫øp t·ª•c quay cho ƒë·∫øn khi ƒë·ªß.`);
          } else {
            setRecording(false);
            recordingRef.current = false;

            if (framesRef.current.length > 0) {
              const quality = computeQuality(framesRef.current);
              onSampleCaptureRef.current(framesRef.current, labelRef.current, userRef.current, { quality_info: quality, dialect: dialectRef.current });
              setFrames([]);
              framesRef.current = [];
            }
          }
        }
      } else if (e.code === 'Escape') {
        console.log('Escape pressed - closing modal');
        handleCloseRef.current?.();
      } else if (e.code === 'Space') {
        // toggle pause/resume when recording
        e.preventDefault();
        if (recordingRef.current) {
          if (pausedRef.current) {
            handleResume();
          } else {
            handlePause();
          }
        }
      } else if (e.code === 'KeyS') {
        // toggle guide
        setShowGuide((s) => !s);
      } else if (e.code === 'KeyD') {
        // toggle tips
        setShowTips((s) => !s);
      } else if (e.code === 'KeyA') {
        // abort/stop current recording and discard partial frames
        if (recordingRef.current) {
          recordingRef.current = false;
          setRecording(false);
          setPaused(false);
          pausedRef.current = false;
          setFrames([]);
          framesRef.current = [];
          setMode('IDLE');
        }
      }
    };

    document.addEventListener('keydown', handleKeyPress);
    return () => document.removeEventListener('keydown', handleKeyPress);
  }, [isOpen, computeQuality, handlePause, handleResume]);

  if (!isOpen) return null;

  console.log('FullscreenCaptureModal rendered, isReady:', isReady, 'recording:', recording, 'countdown:', countdown);

  return (
    <div ref={rootRef} className="fixed inset-0 z-[9999] bg-black">
      {/* Header Bar */}
      <div className="absolute top-0 left-0 right-0 z-10 bg-black/80 backdrop-blur-sm border-b border-gray-700">
        <div className="flex items-center justify-between px-6 py-4">
          <div className="flex items-center space-x-4">
            <h2 className="text-xl font-semibold text-white">üé¨ Ghi to√†n m√†n h√¨nh</h2>
            {isReady && (
              <Badge variant="success">
                <span className="w-2 h-2 bg-green-400 rounded-full animate-pulse mr-2"></span>
                Camera s·∫µn s√†ng
              </Badge>
            )}
          </div>
          
          <div className="flex items-center space-x-4">
            <div className="text-white text-sm">
              Nh·∫•n <kbd className="px-2 py-1 bg-gray-700 rounded text-xs">Enter</kbd> ƒë·ªÉ ch·ª•p ‚Ä¢ <kbd className="px-2 py-1 bg-gray-700 rounded text-xs">Esc</kbd> ƒë·ªÉ tho√°t
            </div>
            <button
              onClick={() => setShowGuide(!showGuide)}
              className="bg-gray-700 hover:bg-gray-600 text-white px-3 py-2 rounded-lg text-sm font-medium transition-all duration-200 flex items-center space-x-2"
            >
              <span>{showGuide ? 'üôà' : 'üëÅÔ∏è'}</span>
              <span>{showGuide ? '·∫®n h∆∞·ªõng d·∫´n' : 'Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n'}</span>
            </button>
            <button
              onClick={handleClose}
              className="text-white hover:text-gray-300 p-2"
            >
              <svg className="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M6 18L18 6M6 6l12 12" />
              </svg>
            </button>
          </div>
        </div>
      </div>

      {/* Main Content */}
      <div className="h-full flex">
        {/* Camera Feed */}
        <div className="flex-1 relative flex items-center justify-center bg-gray-900">
          <video ref={videoRef} autoPlay muted className="hidden" />
          <canvas 
            ref={canvasRef} 
            width={1280} 
            height={720} 
            className="w-full h-full max-w-full max-h-full object-contain border border-gray-600 rounded-lg"
            style={{ minHeight: '400px', backgroundColor: '#1a1a1a' }}
            onLoad={() => console.log('Canvas loaded')}
          />

          {/* Hint overlay when hands are not visible during recording */}
          {recording && !handsVisible && (
            <div className="absolute inset-0 flex items-center justify-center pointer-events-none">
              <div className="bg-black/70 text-yellow-300 px-4 py-2 rounded-lg text-center">
                <div className="font-semibold">Kh√¥ng th·∫•y tay ‚Äî vui l√≤ng hi·ªÉn th·ªã c·∫£ hai tay</div>
                <div className="text-xs mt-1">H·ªá th·ªëng s·∫Ω ch·ªâ l∆∞u khung khi tay ƒë∆∞·ª£c ph√°t hi·ªán</div>
              </div>
            </div>
          )}
          
          {/* Toggle Guide Overlay - Only show when enabled and not recording/countdown */}
          {showGuide && !recording && countdown === 0 && (
            <div className="absolute inset-0 flex items-center justify-center pointer-events-none">
              <div className="relative">
                {/* Compact guide frame - just corner markers */}
                <div className="w-80 h-80 relative">
                  {/* Corner markers only */}
                  <div className="absolute top-0 left-0 w-8 h-8 border-l-4 border-t-4 border-green-400/80 rounded-tl-xl"></div>
                  <div className="absolute top-0 right-0 w-8 h-8 border-r-4 border-t-4 border-green-400/80 rounded-tr-xl"></div>
                  <div className="absolute bottom-0 left-0 w-8 h-8 border-l-4 border-b-4 border-green-400/80 rounded-bl-xl"></div>
                  <div className="absolute bottom-0 right-0 w-8 h-8 border-r-4 border-b-4 border-green-400/80 rounded-br-xl"></div>
                  
                  {/* Center crosshair */}
                  <div className="absolute inset-0 flex items-center justify-center">
                    <div className="w-1 h-8 bg-green-400/60 rounded-full"></div>
                    <div className="absolute w-8 h-1 bg-green-400/60 rounded-full"></div>
                  </div>
                  
                  {/* Hand position indicators - small and subtle */}
                  <div className="absolute top-16 -left-6 w-8 h-8 border border-orange-400/60 rounded-full bg-orange-400/10 flex items-center justify-center">
                    <span className="text-orange-400 text-xs">L</span>
                  </div>
                  <div className="absolute top-16 -right-6 w-8 h-8 border border-teal-400/60 rounded-full bg-teal-400/10 flex items-center justify-center">
                    <span className="text-teal-400 text-xs">R</span>
                  </div>
                </div>
                
                {/* Minimal instruction */}
                <div className="absolute -top-12 left-1/2 transform -translate-x-1/2 bg-gray-800/80 backdrop-blur-sm text-white px-4 py-2 rounded-lg text-sm font-medium">
                  üéØ ƒê·∫∑t v·ªã tr√≠ v√†o khung
                </div>
                
                {/* Quality tip */}
                <div className="absolute -bottom-8 left-1/2 transform -translate-x-1/2 bg-gray-800/70 backdrop-blur-sm text-white px-3 py-1 rounded-lg text-xs">
                  Th·∫•y ph·∫ßn tr√™n c∆° th·ªÉ v√† hai tay
                </div>
              </div>
            </div>
          )}

          {/* Countdown Overlay */}
          {countdown > 0 && (
            <div className="absolute inset-0 flex items-center justify-center bg-black/70 backdrop-blur-sm">
              <div className="text-center text-white">
                <div className="text-8xl font-bold mb-4 animate-pulse">{countdown}</div>
                <div className="text-2xl mb-2">Chu·∫©n b·ªã th·ª±c hi·ªán:</div>
                <div className="text-3xl font-semibold text-green-400">{label}</div>
                {captureCount > 1 && (
                  <div className="text-lg mt-4 text-gray-300">
                    L·∫ßn ch·ª•p {currentCaptureIndex + 1} / {FIXED_CAPTURE_COUNT}
                  </div>
                )}
              </div>
            </div>
          )}

          {/* Paused Overlay */}
          {recording && paused && (
            <div className="absolute inset-0 flex items-center justify-center bg-black/80 backdrop-blur-sm z-20">
              <div className="bg-gray-900 border border-gray-700 rounded-xl p-8 w-[500px]">
                <div className="text-center">
                  <div className="text-6xl mb-4">‚è∏Ô∏è</div>
                  <h3 className="text-3xl font-bold text-white mb-2">ƒê√£ t·∫°m d·ª´ng</h3>
                  <p className="text-gray-300 mb-6">B·∫°n mu·ªën l√†m g√¨ v·ªõi d·ªØ li·ªáu hi·ªán t·∫°i?</p>
                  
                  <div className="bg-gray-800 rounded-lg p-4 mb-6">
                    <div className="flex justify-between text-sm mb-2">
                      <span className="text-gray-400">Ti·∫øn ƒë·ªô:</span>
                      <span className="text-white font-medium">{frames.length} / {FIXED_TARGET_FRAMES} khung</span>
                    </div>
                    <div className="w-full bg-gray-700 rounded-full h-2">
                      <div 
                        className="bg-yellow-500 h-2 rounded-full transition-all duration-300"
                        style={{ width: `${Math.min((frames.length / FIXED_TARGET_FRAMES) * 100, 100)}%` }}
                      />
                    </div>
                  </div>

                  <div className="space-y-3">
                    <button
                      onClick={handleResume}
                      className="w-full px-4 py-3 bg-green-600 hover:bg-green-500 text-white rounded-lg font-medium transition-colors flex items-center justify-center space-x-2"
                    >
                      <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M14.752 11.168l-3.197-2.132A1 1 0 0010 9.87v4.263a1 1 0 001.555.832l3.197-2.132a1 1 0 000-1.664z" />
                        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
                      </svg>
                      <span>Ti·∫øp t·ª•c thu (gi·ªØ {frames.length} khung)</span>
                    </button>
                    
                    <button
                      onClick={handleRestart}
                      className="w-full px-4 py-3 bg-blue-600 hover:bg-blue-500 text-white rounded-lg font-medium transition-colors flex items-center justify-center space-x-2"
                    >
                      <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M4 4v5h.582m15.356 2A8.001 8.001 0 004.582 9m0 0H9m11 11v-5h-.581m0 0a8.003 8.003 0 01-15.357-2m15.357 2H15" />
                      </svg>
                      <span>B·∫Øt ƒë·∫ßu l·∫°i t·ª´ ƒë·∫ßu (x√≥a d·ªØ li·ªáu)</span>
                    </button>

                    {frames.length >= FIXED_TARGET_FRAMES && (
                      <button
                        onClick={() => {
                          setPaused(false);
                          pausedRef.current = false;
                          handleStop();
                        }}
                        className="w-full px-4 py-3 bg-purple-600 hover:bg-purple-500 text-white rounded-lg font-medium transition-colors flex items-center justify-center space-x-2"
                      >
                        <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                          <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M5 13l4 4L19 7" />
                        </svg>
                        <span>Ho√†n t·∫•t v√† l∆∞u</span>
                      </button>
                    )}
                  </div>
                </div>
              </div>
            </div>
          )}

          {/* Between Captures Overlay */}
          {!recording && !countdown && completedCaptures > 0 && completedCaptures < captureCount && (
            <div className="absolute inset-0 flex items-center justify-center bg-black/70 backdrop-blur-sm">
              <div className="text-center text-white">
                <div className="text-4xl mb-4">üéâ</div>
                <div className="text-2xl font-bold mb-2 text-green-400">ƒê√£ ch·ª•p {completedCaptures} m·∫´u!</div>
                <div className="text-xl mb-4">Chu·∫©n b·ªã ch·ª•p ti·∫øp...</div>
                <div className="text-lg text-gray-300">
                  Ti·∫øn ƒë·ªô: {completedCaptures} / {FIXED_CAPTURE_COUNT}
                </div>
                <div className="w-64 bg-gray-700 rounded-full h-3 mt-4 mx-auto">
                  <div 
                    className="bg-green-500 h-3 rounded-full transition-all duration-500"
                    style={{ width: `${(completedCaptures / captureCount) * 100}%` }}
                  />
                </div>
              </div>
            </div>
          )}

          {/* Completion Overlay */}
          {!recording && !countdown && completedCaptures > 0 && completedCaptures >= captureCount && (
            <div className="absolute inset-0 flex items-center justify-center bg-black/80 backdrop-blur-sm">
              <div className="text-center text-white">
                <div className="text-6xl mb-4">‚úÖ</div>
                <div className="text-3xl font-bold mb-2 text-green-400">Ho√†n t·∫•t t·∫•t c·∫£ l·∫ßn ch·ª•p!</div>
                <div className="text-xl mb-4">ƒê√£ ch·ª•p {completedCaptures} m·∫´u cho "{label}"</div>
                <div className="text-lg text-gray-300">S·∫µn s√†ng ch·ª•p ti·∫øp ‚Äî nh·∫≠p nh√£n m·ªõi v√† nh·∫•n n√∫t B·∫Øt ƒë·∫ßu ch·ª•p</div>
              </div>
            </div>
          )}

          {/* Recording Indicator */}
          {recording && (
            <div className="absolute top-24 left-6 flex items-center space-x-3 bg-red-500 text-white px-4 py-2 rounded-full shadow-lg">
              <div className="w-3 h-3 bg-white rounded-full animate-pulse"></div>
              <span className="font-medium">ƒêANG GHI</span>
              {FIXED_CAPTURE_COUNT > 1 && (
                <span className="text-sm">({completedCaptures + 1}/{FIXED_CAPTURE_COUNT})</span>
              )}
            </div>
          )}

          {/* Recording Progress */}
          {recording && (
            <div className="absolute bottom-6 left-1/2 transform -translate-x-1/2 bg-black/50 backdrop-blur-sm rounded-full px-6 py-2">
              <div className="text-white text-sm">
                üìä {frames.length} khung ƒë√£ ch·ª•p
              </div>
            </div>
          )}
        </div>

        {/* Control Panel */}
        <div className="w-96 bg-gray-900 border-l border-gray-700 flex flex-col">
          <div className="flex-1 p-6 space-y-6 overflow-y-auto">
            {/* Enhanced Form Fields with validation */}
            <div className="bg-gradient-to-br from-blue-900/20 to-purple-900/20 rounded-xl p-5 border border-blue-500/20">
              <h3 className="text-lg font-semibold text-white mb-4 flex items-center">
                <span className="w-3 h-3 bg-blue-400 rounded-full mr-3"></span>
                C√†i ƒë·∫∑t ch·ª•p
              </h3>
              
              <div className="space-y-4">
                <div>
                  <label className="block text-sm font-medium text-blue-300 mb-2">üìù Nh√£n h√†nh ƒë·ªông *</label>
                  <div className="relative">
                    <input
                      type="text"
                      value={label}
                      onChange={(e) => setLabel(e.target.value)}
                      placeholder="v√≠ d·ª•: ƒëi b·ªô, nh·∫£y, v·∫´y tay"
                      className="w-full pr-12 px-4 py-3 bg-gray-800/80 border border-gray-600 rounded-lg text-white placeholder-gray-400 focus:ring-2 focus:ring-blue-500 focus:border-blue-500 transition-all duration-200"
                      disabled={recording || countdown > 0}
                    />
                    <div className="absolute inset-y-0 right-2 flex items-center">
                      <SpeechInputButton
                        onText={(text) => setLabel(text)}
                        title="D√πng gi·ªçng n√≥i ƒë·ªÉ ƒëi·ªÅn nh√£n h√†nh ƒë·ªông"
                        className="h-8 w-8"
                      />
                    </div>
                  </div>
                  {!label && (
                    <p className="text-xs text-yellow-400 mt-1">‚ö†Ô∏è Nh√£n h√†nh ƒë·ªông l√† b·∫Øt bu·ªôc</p>
                  )}
                </div>

                <div>
                  <label className="block text-sm font-medium text-blue-300 mb-2">üë§ Ng∆∞·ªùi th·ª±c hi·ªán *</label>
                  <div className="relative">
                    <input
                      type="text"
                      value={user}
                      onChange={(e) => setUser(e.target.value)}
                      placeholder="v√≠ d·ª•: user001, john_doe"
                      className="w-full pr-12 px-4 py-3 bg-gray-800/80 border border-gray-600 rounded-lg text-white placeholder-gray-400 focus:ring-2 focus:ring-blue-500 focus:border-blue-500 transition-all duration-200"
                      disabled={recording || countdown > 0}
                      onBlur={() => rememberUser(user)}
                    />
                    <div className="absolute inset-y-0 right-2 flex items-center">
                      <SpeechInputButton
                        onText={(text) => setUser(text)}
                        title="D√πng gi·ªçng n√≥i ƒë·ªÉ ƒëi·ªÅn t√™n ng∆∞·ªùi th·ª±c hi·ªán"
                        className="h-8 w-8"
                      />
                    </div>
                  </div>
                  {!user && (
                    <p className="text-xs text-yellow-400 mt-1">‚ö†Ô∏è ID ng∆∞·ªùi d√πng l√† b·∫Øt bu·ªôc</p>
                  )}
                  {recentUsers.length > 0 && (
                    <div className="mt-2 flex flex-wrap gap-2 text-xs text-blue-200">
                      <span className="text-[11px] text-blue-300">G·ª£i √Ω:</span>
                      {recentUsers.map((name) => (
                        <button
                          type="button"
                          key={name}
                          onClick={() => setUser(name)}
                          className="px-2 py-1 rounded-full bg-blue-900/60 hover:bg-blue-800 text-blue-100 border border-blue-500/40 text-[11px]"
                        >
                          {name}
                        </button>
                      ))}
                    </div>
                  )}
                </div>

                <div>
                  <label className="block text-sm font-medium text-blue-300 mb-2">üóÇÔ∏è B·ªô ng√¥n ng·ªØ</label>
                  <select
                    value={dialect}
                    onChange={(e) => {
                      const v = e.target.value;
                      if (v === 'Kh√°c') {
                        const name = window.prompt('Nh·∫≠p t√™n b·ªô m·ªõi:');
                        if (name && name.trim()) {
                          const updated = Array.from(new Set([...dialectList, name.trim()]));
                          setDialectList(updated);
                          setDialect(name.trim());
                          localStorage.setItem('dialectList', JSON.stringify(updated));
                          localStorage.setItem('dialectSelected', name.trim());
                        }
                      } else {
                        setDialect(v);
                        localStorage.setItem('dialectSelected', v);
                      }
                    }}
                    className="w-full px-4 py-3 bg-gray-800/80 border border-gray-600 rounded-lg text-white placeholder-gray-400 focus:ring-2 focus:ring-blue-500 focus:border-blue-500 transition-all duration-200"
                    disabled={recording || countdown > 0}
                  >
                    {dialectList.map((d) => (
                      <option key={d} value={d}>{d}</option>
                    ))}
                    <option value="Kh√°c">Kh√°c (th√™m m·ªõi)</option>
                  </select>
                </div>
              </div>
            </div>

            {/* Quick labels removed for public-facing modal to simplify UX */}

            {/* Recording Stats */}
            <div className="bg-gray-800 rounded-lg p-4">
              <h4 className="text-sm font-medium text-gray-300 mb-3">üìä C√†i ƒë·∫∑t & Ti·∫øn ƒë·ªô ch·ª•p</h4>
              <div className="space-y-2 text-sm">
                {/* Capture settings removed for simplified public uploader; defaults are enforced. */}
                <div className="flex justify-between text-gray-400">
                  <span>T·ªïng s·ªë l·∫ßn ch·ª•p:</span>
                  <span className="text-white">{FIXED_CAPTURE_COUNT}</span>
                </div>
                <div className="flex justify-between text-gray-400">
                  <span>L·∫ßn ch·ª•p hi·ªán t·∫°i:</span>
                  <span className="text-white">{currentCaptureIndex + 1}/{FIXED_CAPTURE_COUNT}</span>
                </div>
                <div className="flex justify-between text-gray-400">
                  <span>ƒê√£ ho√†n th√†nh:</span>
                  <span className="text-white">{completedCaptures}/{FIXED_CAPTURE_COUNT}</span>
                </div>
                <div className="flex justify-between text-gray-400">
                  <span>Khung hi·ªán t·∫°i:</span>
                  <span className="text-white">{frames.length}/{FIXED_TARGET_FRAMES}</span>
                </div>
                {frames.length > 0 && (
                  <div className="w-full bg-gray-700 rounded-full h-2 mt-2">
                    <div 
                      className="bg-blue-600 h-2 rounded-full transition-all duration-300"
                      style={{ width: `${Math.min((frames.length / FIXED_TARGET_FRAMES) * 100, 100)}%` }}
                    />
                  </div>
                )}
                <div className="flex justify-between text-gray-400">
                  <span>Tr·∫°ng th√°i:</span>
                  <Badge variant={recording ? "danger" : isReady ? "success" : "warning"} size="sm">
                    {recording ? "ƒêang ghi" : isReady ? "S·∫µn s√†ng" : "ƒêang t·∫£i"}
                  </Badge>
                </div>
              </div>
            </div>
          </div>

          {/* Action Buttons */}
          <div className="p-6 border-t border-gray-700 space-y-3">
            {countdown > 0 ? (
              <div className="w-full py-4 bg-yellow-600 text-white rounded-lg text-center font-medium">
                B·∫Øt ƒë·∫ßu sau {countdown}...
              </div>
            ) : !recording ? (
              <Button
                onClick={handleQuickCapture}
                disabled={!label || !user || !isReady}
                className="w-full py-4 text-lg font-medium"
                variant="primary"
              >
                <svg className="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M13 10V3L4 14h7v7l9-11h-7z" />
                </svg>
                {FIXED_CAPTURE_COUNT > 1 ? `B·∫Øt ƒë·∫ßu ch·ª•p (${FIXED_CAPTURE_COUNT}x)` : 'B·∫Øt ƒë·∫ßu ch·ª•p'} (Enter)
              </Button>
            ) : paused ? (
              <div className="text-center py-4 text-gray-400">
                <span className="text-yellow-500 font-medium">‚è∏ ƒê√£ t·∫°m d·ª´ng</span>
                <p className="text-sm mt-1">Xem c√°c t√πy ch·ªçn tr√™n m√†n h√¨nh</p>
              </div>
            ) : (
              <>
                <Button
                  onClick={handlePause}
                  className="w-full py-4 text-lg font-medium bg-yellow-600 hover:bg-yellow-500"
                  variant="secondary"
                >
                  <svg className="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M10 9v6m4-6v6m7-3a9 9 0 11-18 0 9 9 0 0118 0z" />
                  </svg>
                  T·∫°m d·ª´ng (Space)
                </Button>
                <Button
                  onClick={handleStop}
                  className="w-full py-3"
                  variant="danger"
                  disabled={frames.length < FIXED_TARGET_FRAMES}
                  title={frames.length < FIXED_TARGET_FRAMES ? `C·∫ßn ${FIXED_TARGET_FRAMES} khung tr∆∞·ªõc khi d·ª´ng` : undefined}
                >
                  <svg className="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M9 9h6v6H9z" />
                  </svg>
                  D·ª´ng v√† l∆∞u
                </Button>
              </>
            )}
            
            <Button
              onClick={handleClose}
              className="w-full"
              variant="secondary"
            >
              Tho√°t to√†n m√†n h√¨nh
            </Button>
          </div>

          {/* Collapsible Tips Footer */}
          <div className="bg-gray-800 border-t border-gray-700 p-4">
            <button
              onClick={() => setShowTips(!showTips)}
              className="w-full flex items-center justify-between text-sm font-medium text-gray-300 hover:text-white transition-colors"
            >
              <span>üí° M·∫πo nhanh ƒë·ªÉ c√≥ k·∫øt qu·∫£ t·ªët</span>
              <span className="text-xs">{showTips ? 'üîΩ' : '‚ñ∂Ô∏è'}</span>
            </button>
            
            {showTips && (
              <div className="mt-3 grid grid-cols-2 gap-2 text-xs text-gray-400">
                <div>‚ú® ƒê·∫£m b·∫£o √°nh s√°ng t·ªët v√† n·ªÅn r√µ r√†ng</div>
                <div>ü§≤ Gi·ªØ tay hi·ªÉn th·ªã v√† ng√≥n tay du·ªói</div>
                <div>üëÅÔ∏è D√πng n√∫t "Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n" ƒë·ªÉ h·ªó tr·ª£ ƒë·ªãnh v·ªã</div>
                <div>üîó Quan s√°t k·∫øt n·ªëi gi·ªØa c√°c b·ªô ph·∫≠n tay ƒë·ªÉ theo d√µi t·ªët h∆°n</div>
                <div>üéØ Gi·ªØ ·ªü gi·ªØa khung h√¨nh</div>
                <div>‚ö° Di chuy·ªÉn t·ª± nhi√™n ƒë·ªÉ c√≥ k·∫øt qu·∫£ t·ªët nh·∫•t</div>
              </div>
            )}
          </div>
        </div>
      </div>
    </div>
  );
}